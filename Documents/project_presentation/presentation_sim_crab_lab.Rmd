---
title: "Simulations for short term health effects of air pollution"
author: "Vincent Bagilet - Leo Zabrocki"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      countIncrementalSlides: no
      highlightLines: yes
      highlightStyle: github
  slidy_presentation:
    highlight: pygments
  github_document: default
  html_notebook:
    highlight: pygments
    theme: simplex
    toc: yes
  ioslides_presentation:
    highlight: pygments
  pdf_document:
    includes:
      in_header: VB_markdown.sty
    keep_tex: yes
  html_document:
    highlight: pygments
    theme: simplex
  beamer_presentation:
    highlight: pygments
    theme: VB_Beamer
subtitle: "ðŸ¦€ lab presentation"
---

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_light(
  base_color = "#00313C", #1B2754
  text_color = "#00313C",
  background_color = "#F9FAF7",
  header_font_google = google_font("Josefin Sans", "400"),
  text_font_google   = google_font("Lato", "400", "400i"),
  header_font_weight = "bold",
  text_bold_color = "#81402C", #"#B67F10",
  link_color = "#81402C",
  text_font_size = "22px",
  header_h1_font_size = "45px",
  header_h2_font_size = "35px",
  header_h3_font_size = "25px",
  text_slide_number_font_size = "16px"
)
```

# Summary of the main questions

- What is the usual **power** in studies of short-term health effects of air pollution? âœ”ï¸
  
- How do **different identification strategies** perform to estimate these effects?
  
- What is the impact of **missing data** on these estimates? 

```{r echo=FALSE, out.width= 400, fig.align="center"} 
knitr::include_graphics("images/pollution_paris.jpg")
```
  
- Today: simulations to answer the second question

---

## Motivation

- Effects are really small => difficult to detect

- "Fancy" techniques developed to avoid omitted variable bias but it may create another type of bias: type M and type S error

- Good exercise for us, PhD students

## Overall method

- Consider RCTs, DiDs, ITSs, RDDs and later IVs and Poisson generalized additive models

1. Assign treatment randomly
1. Create the number of deaths if unit would have been treated (Y(1))
1. Run our estimation
1. Store estimates and p-values
1. Repeat
1. Compute the average bias, power, type M, type S

---

## Data

- 18 cities in France 

- 2013-2018 

- Hospital admissions and deaths 

- Air pollution concentration 

- Weather variables 

- Calendar control variables 

- Daily and city level: a unique observation per date and per city in the data set

---

## Background on selected designs

### RCT

- Changes in air pollution levels on some random days. 

- Example: transportation strikes 

- For now, treated days defined at random. Later, deviations

- Compares the average number of deaths in cities with treatment to cities with no treatment on the same day, controlling for differences across cities.

### DID

- Changes in air pollution levels in a subset of cities after a given date. 

- Examples change in regulations at a sub-national level 

- Same comparison as RCT but non-random treatment assignment 

???

- RCT: compare the average number of deaths or hospital admissions in cities with treatment to cities with no treatment on the same day, controlling for differences across cities.

---

ITS

Here consider interventions leading to changes in air pollution levels in a subset of cities after a given date. Examples of such interventions include an air pollution reduction policy at a sub-national level or a change in regulations at a sub-national level leading to an increase in pollution level.

The overall idea of the ITS is to compare the average number of deaths or hospital admissions before and after treatment.
RDD

Here consider interventions that affect exposure to air pollution when air pollution levels reach a given threshold. Examples of such interventions include air pollution alerts: when pollution reaches a certain level, alerts are released, inviting people to reduce their exposure.

The overall idea of the RDD is to compare days just below the threshold to days just above the threshold (where exposure and health impacts are thus lower). The assumption is that days just below and just above the threshold are comparable.

---

## Method

- For the sake of the example, let's focus on a simple Poisson generalized additive model:

$$h_{ct} = \alpha + \beta_{c}p_{ct} + \boldsymbol{W_{ct}'\delta} +  \boldsymbol{C_{ct}'\gamma} + \epsilon_{ct}$$
- Use both actual and fake data (here focus on actual data)

1. Estimate the model on the existing data

--

1. Define a "fake", known, effect $\beta_c$

--

1. Generate noise $(\epsilon)$ and predict/generate fake hospital admission and mortality data $(h)$ based on our estimated model (1000 data sets)

--

1. Reestimate the model to see if we recover our true value

--

1. Compute bias, power, type I, type M, type S error

---

- Look how our measures of interest vary with sample size and effect size.

- Where do papers in the literature lie? $\to$ what problem could it be exposed to

- Repeat this for each identification strategy (with different DGPs of course)

- Reproduce the same analysis with fake data (*ie* generate all the data)

---

## Definitions

- **Power**: probability of finding an effect when there is actually one

- Power can be low when effects are small and/or variance of the estimates is large (*eg* small sample size)

```{r echo=FALSE, out.width= 600, fig.align="center"} 
knitr::include_graphics("images/typeMS_own.png")
```


